
@article{duong_under-determined_2009,
	title = {Under-determined reverberant audio source separation using a full-rank spatial covariance model},
	url = {http://arxiv.org/abs/0912.0171},
	abstract = {This article addresses the modeling of reverberant recording environments in the context of under-determined convolutive blind source separation. We model the contribution of each source to all mixture channels in the time-frequency domain as a zero-mean Gaussian random variable whose covariance encodes the spatial characteristics of the source. We then consider four speciﬁc covariance models, including a full-rank unconstrained model. We derive a family of iterative expectation-maximization (EM) algorithms to estimate the parameters of each model and propose suitable procedures to initialize the parameters and to align the order of the estimated sources across all frequency bins based on their estimated directions of arrival (DOA). Experimental results over reverberant synthetic mixtures and live recordings of speech data show the eﬀectiveness of the proposed approach.},
	language = {en},
	urldate = {2020-02-26},
	journal = {arXiv:0912.0171 [stat]},
	author = {Duong, Ngoc and Vincent, Emmanuel and Gribonval, Remi},
	month = dec,
	year = {2009},
	note = {arXiv: 0912.0171},
	keywords = {Statistics - Machine Learning},
	file = {Under-determined reverberant audio source separation using a full-rank spatial covariance model.pdf:/Users/andres.perez/Documents/papers/Under-determined reverberant audio source separation using a full-rank spatial covariance model.pdf:application/pdf}
}

@incollection{elko_spatial_2001,
	address = {New York},
	title = {Spatial coherence functions for differential microphones in isotropic noise fields},
	booktitle = {Microphone {Arrays}},
	publisher = {Springer},
	author = {Elko, Gary W.},
	year = {2001},
	pages = {61--85}
}

@article{epain2016spherical,
  title={Spherical harmonic signal covariance and sound field diffuseness},
  author={Epain, Nicolas and Jin, Craig T},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={24},
  number={10},
  pages={1796--1807},
  year={2016},
  publisher={IEEE}
}


@inproceedings{gerzon1975design,
  title={The design of precisely coincident microphone arrays for stereo and surround sound},
  author={Gerzon, Michael A},
  booktitle={Audio Engineering Society Convention 50},
  year={1975},
  organization={Audio Engineering Society}
}

@article{habets_generating_2007,
	title = {Generating sensor signals in isotropic noise fields},
	volume = {122},
	issn = {0001-4966},
	url = {http://asa.scitation.org/doi/10.1121/1.2799929},
	doi = {10.1121/1.2799929},
	language = {en},
	number = {6},
	urldate = {2020-02-26},
	journal = {The Journal of the Acoustical Society of America},
	author = {Habets, Emanuel A. P. and Gannot, Sharon},
	month = dec,
	year = {2007},
	pages = {3464--3470},
	file = {Generating sensor signals in isotropic noise fields.pdf:/Users/andres.perez/Documents/papers/Generating sensor signals in isotropic noise fields.pdf:application/pdf}
}

@article{habets_comments_2010,
	title = {Comments on Generating sensor signals in isotropic noise fields},
	author = {Habets, Emanuel A. P. and Gannot, Sharon},
	year = {2010},
}

@inproceedings{p_habets_dual-microphone_2006,
	address = {Vancouver, BC, Canada},
	title = {Dual-{Microphone} {Speech} {Dereverberation} in a {Noisy} {Environment}},
	isbn = {978-0-7803-9754-5 978-0-7803-9753-8},
	url = {http://ieeexplore.ieee.org/document/4042323/},
	doi = {10.1109/ISSPIT.2006.270881},
	abstract = {Speech signals recorded with a distant microphone usually contain reverberation and noise, which degrade the ﬁdelity and intelligibility of speech, and the recognition performance of automatic speech recognition systems. In [1] Habets presented a multi-microphone speech dereverberation algorithm to suppress late reverberation in a noise-free environment. In this paper we show how an estimate of the late reverberant energy can be obtained from noisy observations. A more sophisticated speech enhancement technique based on the Optimally-Modiﬁed Log Spectral Amplitude (OM-LSA) estimator is used to suppress the undesired late reverberant signal and noise. The speech presence probability used in the OM-LSA is extended to improve the decision between speech, late reverberation and noise. Experiments using simulated and real acoustic impulse responses are presented and show signiﬁcant reverberation reduction with little speech distortion.},
	language = {en},
	urldate = {2020-02-26},
	booktitle = {2006 {IEEE} {International} {Symposium} on {Signal} {Processing} and {Information} {Technology}},
	publisher = {IEEE},
	author = {P. Habets, Emanuel and Gannot, Sharon and Cohen, Israel},
	month = aug,
	year = {2006},
	pages = {651--655},
	file = {Dual-Microphone Speech Dereverberation in a Noisy Environment.pdf:/Users/andres.perez/Documents/papers/Dual-Microphone Speech Dereverberation in a Noisy Environment.pdf:application/pdf}
}

@inproceedings{ito_designing_2010,
	address = {Dallas, TX, USA},
	title = {Designing the {Wiener} post-filter for diffuse noise suppression using imaginary parts of inter-channel cross-spectra},
	isbn = {978-1-4244-4295-9},
	url = {http://ieeexplore.ieee.org/document/5496202/},
	doi = {10.1109/ICASSP.2010.5496202},
	abstract = {This paper describes a new design of the Wiener post-ﬁlter for diffuse noise suppression. The Wiener post-ﬁlter is well-known as an effective post-processing of the minimum variance distortionless response beamformer, and its output is the optimal estimate of the target signal in the sense of the minimum mean square error. It is essential to accurately estimate the target power spectrum from the observed signals contaminated by noise when designing the Wiener post-ﬁlter. In our method, it is estimated from the imaginary parts of the inter-channel observation cross-spectra, under the assumption that the inter-channel noise cross-spectra are real-valued. The postﬁlter is designed using the estimate and this design is shown to be effective even for a small-sized array through experiments using simulated and real environmental noise.},
	language = {en},
	urldate = {2020-02-26},
	booktitle = {2010 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	publisher = {IEEE},
	author = {Ito, Nobutaka and Ono, Nobutaka and Vincent, Emmanuel and Sagayama, Shigeki},
	year = {2010},
	pages = {2818--2821},
	file = {Designing the Wiener post-filter for diffuse noise suppression using imaginary parts of inter-channel cross-spectra.pdf:/Users/andres.perez/Documents/papers/Designing the Wiener post-filter for diffuse noise suppression using imaginary parts of inter-channel cross-spectra.pdf:application/pdf}
}

@article{mccowan_microphone_2003,
	title = {Microphone array post-filter based on noise field coherence},
	volume = {11},
	issn = {1063-6676},
	url = {http://ieeexplore.ieee.org/document/1255457/},
	doi = {10.1109/TSA.2003.818212},
	abstract = {This paper introduces a novel technique for estimating the signal power spectral density to be used in the transfer function of a microphone array post-filter. The technique is a generalization of the existing Zelinski post-filter, which uses the auto- and cross-spectral densities of the array inputs to estimate the signal and noise spectral densities. The Zelinski technique, however, assumes zero cross-correlation between the noise on different sensors. This assumption is inaccurate, particularly at low frequencies and for arrays with closely spaced sensors, and thus the corresponding post-filter is suboptimal in realistic noise conditions. In this paper, a more general expression of the post-filter estimation is developed based on an assumed knowledge of the complex coherence of the noise field. This general expression can be used to construct a more appropriate post-filter in a variety of different noise fields. In experiments using real noise recordings from a computer office, the modified post-filter results in significant improvement in terms of objective speech quality measures and speech recognition performance using a diffuse noise model.},
	language = {en},
	number = {6},
	urldate = {2020-02-26},
	journal = {IEEE Transactions on Speech and Audio Processing},
	author = {McCowan, I.A. and Bourlard, H.},
	month = nov,
	year = {2003},
	pages = {709--716},
	file = {Microphone Array Post-Filter Based on Noise Field Coherence.pdf:/Users/andres.perez/Documents/papers/Microphone Array Post-Filter Based on Noise Field Coherence.pdf:application/pdf}
}

@article{bertet_3d_2006,
	title = {{3D} {Sound} {Field} {Recording} with {Higher} {Order} {Ambisonics} - {Objective} {Measurements} and {Validation} of {Spherical} {Microphone}},
	abstract = {Higher Order Ambisonics (HOA) is a flexible approach for representing and rendering 3D sound fields. Nevertheless, lack of effective microphone systems limited its use until recently. As a result of authors’ previous work on the theory and design of spherical microphone arrays, a 4th order HOA microphone has been built, measured and used for natural recording. The present paper first discusses theoretical aspects and physical limitations proper to discrete, relatively small arrays (spatial aliasing, low-frequency estimation). Then it focuses on the objective validation of such microphones. HOA directivities reconstructed from simulated and measured 3D responses are compared to the expected spherical harmonics. Criteria like spatial correlation help characterizing the encoding artifacts due to the model limitations and the prototype imperfections. Impacts on localisation criteria are evaluated.},
	language = {en},
	author = {Bertet, Stéphanie and Daniel, Jérôme and Moreau, Sébastien},
	year = {2006},
	pages = {24},
	file = {3D Sound Field Recording with Higher Order Ambisonics - Objective Measurements and Validation of Spherical Microphone.pdf:/Users/andres.perez/Documents/papers/3D Sound Field Recording with Higher Order Ambisonics - Objective Measurements and Validation of Spherical Microphone.pdf:application/pdf}
}

@article{motlicek_real-time_2013,
	title = {Real-{Time} {Audio}-{Visual} {Analysis} for {Multiperson} {Videoconferencing}},
	volume = {2013},
	issn = {1687-5680, 1687-5699},
	url = {http://www.hindawi.com/journals/am/2013/175745/},
	doi = {10.1155/2013/175745},
	abstract = {We describe the design of a system consisting of several state-of-the-art real-time audio and video processing components enabling multimodal stream manipulation (e.g., automatic online editing for multiparty videoconferencing applications) in open, unconstrained environments. The underlying algorithms are designed to allow multiple people to enter, interact, and leave the observable scene with no constraints. They comprise continuous localisation of audio objects and its application for spatial audio object coding, detection, and tracking of faces, estimation of head poses and visual focus of attention, detection and localisation of verbal and paralinguistic events, and the association and fusion of these different events. Combined all together, they represent multimodal streams with audio objects and semantic video objects and provide semantic information for stream manipulation systems (like a virtual director). Various experiments have been performed to evaluate the performance of the system. The obtained results demonstrate the effectiveness of the proposed design, the various algorithms, and the benefit of fusing different modalities in this scenario.},
	language = {en},
	urldate = {2020-02-26},
	journal = {Advances in Multimedia},
	author = {Motlicek, Petr and Duffner, Stefan and Korchagin, Danil and Bourlard, Hervé and Scheffler, Carl and Odobez, Jean-Marc and Del Galdo, Giovanni and Kallinger, Markus and Thiergart, Oliver},
	year = {2013},
	pages = {1--21},
	file = {Real-Time Audio-Visual Analysis for Multiperson Videoconferencing.pdf:/Users/andres.perez/Documents/papers/Real-Time Audio-Visual Analysis for Multiperson Videoconferencing.pdf:application/pdf}
}

@inproceedings{politis_direction--arrival_2015,
	address = {South Brisbane, Queensland, Australia},
	title = {Direction-of-arrival and diffuseness estimation above spatial aliasing for symmetrical directional microphone arrays},
	isbn = {978-1-4673-6997-8},
	url = {http://ieeexplore.ieee.org/document/7177921/},
	doi = {10.1109/ICASSP.2015.7177921},
	abstract = {A method for direction-of-arrival (DOA) and diffuseness estimation is presented, which proves to be effective above the spatial aliasing frequency of the microphone array in use. The method assumes symmetrical circular or spherical arrays of directional microphones or microphone mounted on a rigid bafﬂe, and it exploits the inherent directionality of the array at high frequencies. The DOA and diffuseness estimators are shown to exhibit low estimation error above the spatial aliasing limit, compared to commonly used intensity-based estimators. A low-error broadband scheme that combines the intensity-based method and the new one is proposed for the ranges below and above aliasing respectively.},
	language = {en},
	urldate = {2020-02-26},
	booktitle = {2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Politis, Archontis and Delikaris-Manias, Symeon and Pulkki, Ville},
	month = apr,
	year = {2015},
	pages = {6--10},
	file = {Direction-of-Arrival and Diffuseness Estimation Above Spatial Aliasing for Symmetrical Directional Microphone Arrays.pdf:/Users/andres.perez/Documents/papers/Direction-of-Arrival and Diffuseness Estimation Above Spatial Aliasing for Symmetrical Directional Microphone Arrays.pdf:application/pdf}
}

@inproceedings{politis_compass_2018,
	address = {Calgary, AB},
	title = {{COMPASS}: {Coding} and {Multidirectional} {Parameterization} of {Ambisonic} {Sound} {Scenes}},
	isbn = {978-1-5386-4658-8},
	shorttitle = {{COMPASS}},
	url = {https://ieeexplore.ieee.org/document/8462608/},
	doi = {10.1109/ICASSP.2018.8462608},
	abstract = {Current methods for immersive playback of spatial sound content aim at ﬂexibility in terms of encoding and decoding, abstracting the two from the recording or playback setup. Ambisonics constitutes such a method, that is however signal-independent, and at low spatial resolutions fails to provide appropriate spatialization cues to the listener, with potential severe colouration effects and localization ambiguity. We present a new signal-dependent method for parametric analysis and synthesis of ambisonic sound scenes that takes advantage of the ﬂexibility of Ambisonics as a spatial audio format, while improving reproduction. The proposed approach considers a more general acoustic model than previous proposals, with multiple source signals and a non isotropic ambient component. According to a listening test using headphones, the method is perceived closer to binaural reference sound scenes than ambisonic playback.},
	language = {en},
	urldate = {2020-02-26},
	booktitle = {2018 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Politis, Archontis and Tervo, Sakari and Pulkki, Ville},
	month = apr,
	year = {2018},
	pages = {6802--6806},
	file = {COMPASS Coding and Multidirectional Parameterization of Ambisonic Sound Scenes.pdf:/Users/andres.perez/Documents/papers/COMPASS Coding and Multidirectional Parameterization of Ambisonic Sound Scenes.pdf:application/pdf}
}

@inproceedings{pulkki2006directional,
  title={Directional audio coding in spatial sound reproduction and stereo upmixing},
  author={Pulkki, Ville},
  booktitle={Audio Engineering Society Conference: 28th International Conference: The Future of Audio Technology--Surround and Beyond},
  year={2006},
  organization={Audio Engineering Society}
}

@inproceedings{schorkhuber_ambisonic_2017,
  title={Ambisonic microphone encoding with covariance constraint},
  author={Sch{\"o}rkhuber, Christian and H{\"o}ldrich, Robert},
  booktitle={Proceedings of the International Conference on Spatial Audio},
  pages={7--10},
  year={2017}
}

@inproceedings{stefanakis_foreground_2015,
	address = {South Brisbane, Queensland, Australia},
	title = {Foreground suppression for capturing and reproduction of crowded acoustic environments},
	isbn = {978-1-4673-6997-8},
	url = {http://ieeexplore.ieee.org/document/7177930/},
	doi = {10.1109/ICASSP.2015.7177930},
	abstract = {Traditionally, sensor arrays and spatial ﬁltering aim to enhance individual sources by suppressing ambient noise and reverberation. In this paper, the exactly opposite problem is examined, that of suppressing individual sources in favour of the ambient sound and of the whole acoustic scene in general. We consider a compact circular sensor array which is embedded in a crowded ambient acoustic environment and is at the same time prone to interference from directional speech originating from multiple nearby speakers. We propose a method for suppressing the undesired components and we compare its performance with two established approaches in spatial audio processing, namely, direct-to-diffuse decomposition and PrimaryAmbient Extraction (PAE). Experimental results and a listening test which are presented illustrate the superiority of our method.},
	language = {en},
	urldate = {2020-02-26},
	booktitle = {2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Stefanakis, Nikolaos and Mouchtaris, Athanasios},
	month = apr,
	year = {2015},
	pages = {51--55},
	file = {Foreground suppression for capturing and reproduction of crowded acoustic environments.pdf:/Users/andres.perez/Documents/papers/Foreground suppression for capturing and reproduction of crowded acoustic environments.pdf:application/pdf}
}

@inproceedings{thiergart_diffuseness_2011,
	address = {New Paltz, NY, USA},
	title = {Diffuseness estimation with high temporal resolution via spatial coherence between virtual first-order microphones},
	isbn = {978-1-4577-0693-6 978-1-4577-0692-9 978-1-4577-0691-2},
	url = {http://ieeexplore.ieee.org/document/6082269/},
	doi = {10.1109/ASPAA.2011.6082269},
	abstract = {The diffuseness of sound can be estimated with practical microphone setups by considering the spatial coherence between two microphone signals. In applications where small arrays of omnidirectional microphones are preferred, the diffuseness estimation is impaired by a high signal coherence in diffuse ﬁelds at lower frequencies, which is particularly problematic when carrying out the estimation with high temporal resolution. Therefore, we propose to exploit the spatial coherence between two virtual ﬁrst-order microphones derived from the omnidirectional array. This represents a ﬂexible method to accurately estimate the diffuseness in high-SNR regions at lower frequencies with high temporal resolution.},
	language = {en},
	urldate = {2020-02-26},
	booktitle = {2011 {IEEE} {Workshop} on {Applications} of {Signal} {Processing} to {Audio} and {Acoustics} ({WASPAA})},
	publisher = {IEEE},
	author = {Thiergart, Oliver and Galdo, Giovanni Del and Habets, Emanuel A. P.},
	month = oct,
	year = {2011},
	pages = {217--220},
	file = {Diffuseness estimation with high temporal resolution via spatial coherence between virtual first-order microphones.pdf:/Users/andres.perez/Documents/papers/Diffuseness estimation with high temporal resolution via spatial coherence between virtual first-order microphones.pdf:application/pdf}
}


@inproceedings{thiergart_localization_2009,
  title={Localization of sound sources in reverberant environments based on directional audio coding parameters},
  author={Thiergart, Oliver and Schultz-Amling, Richard and Del Galdo, Giovanni and Mahne, Dirk and Kuech, Fabian},
  booktitle={Audio Engineering Society Convention 127},
  year={2009},
  organization={Audio Engineering Society}
}

@article{zotter_all-round_2012,
	title = {All-{Round} {Ambisonic} {Panning} and {Decoding}},
	volume = {60},
	language = {en},
	number = {10},
	journal = {J. Audio Eng. Soc.},
	author = {Zotter, Franz and Frank, Matthias},
	year = {2012},
	pages = {14},
	file = {All-Round Ambisonic Panning and Decoding.pdf:/Users/andres.perez/Documents/papers/All-Round Ambisonic Panning and Decoding.pdf:application/pdf}
}

@misc{sennheiser,
    author = {Sennheiser},
    title = {Ambeo VR Mic},
    year = {2020},
	note={Accessed on June 26th, 2020},
    howpublished={\url{https://en-us.sennheiser.com/microphone-3d-audio-ambeo-vr-mic}}
}

